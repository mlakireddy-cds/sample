{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7rc1"
    },
    "colab": {
      "name": "M1_AST_06_Frequentist_Inference_C.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mlakireddy-cds/sample/blob/main/M1_AST_06_Frequentist_Inference_C.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "alive-yukon"
      },
      "source": [
        "# Advanced Certification Program in Computational Data Science\n",
        "## A program by IISc and TalentSprint\n",
        "### Assignment 6: Frequentist Inference"
      ],
      "id": "alive-yukon"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "alternative-maldives"
      },
      "source": [
        "## Learning Objectives"
      ],
      "id": "alternative-maldives"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "interpreted-mainland"
      },
      "source": [
        "At the end of the experiment, you will be able to\n",
        "\n",
        "* understand the different view points of the frequentist and Bayesian approaches\n",
        "* understand the basic idea behind statistical hypothesis testing\n",
        "* Interpret the P-values and R-squared in linear regression analysis"
      ],
      "id": "interpreted-mainland"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "political-relay"
      },
      "source": [
        "## Information"
      ],
      "id": "political-relay"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "coastal-development"
      },
      "source": [
        "**Frequentist inference** is a collection of error probabilistic methods which allows us to learn from data about the true state of nature in the presence of uncertainty by using model-based inference. It's core goal involves providing error control in the face of uncertainty. It was developed in the early 20-th century by Fisher, Neyman & Pearson, and others, largely replacing the present approaches to statistical inference, among them Bayesian inference.\n"
      ],
      "id": "coastal-development"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "productive-register"
      },
      "source": [
        "Imagine that a hospital has hired you as their data analyst. An administrator is working on the hospital's business operations plan and needs you to help them answer some business questions. In this assignment notebook, we use frequentist statistical inference on a data sample to answer the questions.\n",
        "\n",
        "* has the hospital's revenue stream fallen below a key threshold?\n",
        "* are patients with insurance really charged different amounts than those without? \n",
        "\n",
        "Answering that last question with a frequentist approach makes some assumptions, or requires some knowledge, about the two groups.\n",
        "\n",
        "We introduced the Central Limit Theorem (CLT), and how it tells us that the distributions of sample statistics approach a normal distribution as $n$ increases. The amazing thing about this is that it applies to the sampling distributions of statistics that have been calculated from even highly non-normal distributions of data. Remember, also, that hypothesis testing is very much based on making inferences about such sample statistics. We're going to rely heavily on the CLT to apply frequentist (parametric) tests to answer the questions in this notebook."
      ],
      "id": "productive-register"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "corrected-greene"
      },
      "source": [
        "### Dataset"
      ],
      "id": "corrected-greene"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "spectacular-arena"
      },
      "source": [
        "#### Dataset Descrition\n",
        "\n",
        "Dataset chosen for this assignment is [medical charges sample insurances](https://www.kaggle.com/easonlai/sample-insurance-claim-prediction-dataset).  The dataset is made up of 1338 records and 8 columns. It includes important attributes of the Medical Charges. Each record contains the values for\n",
        "\n",
        "- age: age of policyholder\n",
        "- sex: gender of policy holder (female=0, male=1)\n",
        "- bmi: Body mass index, providing an understanding of body, weights that are relatively high or low relative to height, objective index of body weight $(kg / m^2)$ using the ratio of height to weight, ideally 18.5 to 25\n",
        "- steps: average walking steps per day of policyholder\n",
        "- children: number of children / dependents of policyholder\n",
        "- smoker: smoking state of policyholder (non-smoke=0;smoker=1)\n",
        "- region: the residential area of policyholder in the US (northeast=0, northwest=1, southeast=2, southwest=3)\n",
        "- charges: individual medical costs billed by health insurance\n",
        "- insuranceclaim: yes=1, no=0"
      ],
      "id": "spectacular-arena"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BNLA8HiKxQhc"
      },
      "source": [
        "### Setup Steps:"
      ],
      "id": "BNLA8HiKxQhc"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2YzfoPvJDiTX"
      },
      "source": [
        "#@title Please enter your registration id to start: { run: \"auto\", display-mode: \"form\" }\n",
        "Id = \"\" #@param {type:\"string\"}"
      ],
      "id": "2YzfoPvJDiTX",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AjoZJWGErxGf"
      },
      "source": [
        "#@title Please enter your password (your registered phone number) to continue: { run: \"auto\", display-mode: \"form\" }\n",
        "password = \"\" #@param {type:\"string\"}"
      ],
      "id": "AjoZJWGErxGf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WBPPuGmBlDIN",
        "cellView": "form"
      },
      "source": [
        "#@title Run this cell to complete the setup for this Notebook\n",
        "from IPython import get_ipython\n",
        "\n",
        "ipython = get_ipython()\n",
        "  \n",
        "notebook= \"M1_AST_06_Frequentist_Inference_C\" #name of the notebook\n",
        "\n",
        "def setup():\n",
        "#  ipython.magic(\"sx pip3 install torch\")  \n",
        "    ipython.magic(\"sx wget https://cdn.iisc.talentsprint.com/CDS/Datasets/insurance2.csv\")\n",
        "    from IPython.display import HTML, display\n",
        "    display(HTML('<script src=\"https://dashboard.talentsprint.com/aiml/record_ip.html?traineeId={0}&recordId={1}\"></script>'.format(getId(),submission_id)))\n",
        "    print(\"Setup completed successfully\")\n",
        "    return\n",
        "\n",
        "def submit_notebook():\n",
        "    ipython.magic(\"notebook -e \"+ notebook + \".ipynb\")\n",
        "    \n",
        "    import requests, json, base64, datetime\n",
        "\n",
        "    url = \"https://dashboard.talentsprint.com/xp/app/save_notebook_attempts\"\n",
        "    if not submission_id:\n",
        "      data = {\"id\" : getId(), \"notebook\" : notebook, \"mobile\" : getPassword()}\n",
        "      r = requests.post(url, data = data)\n",
        "      r = json.loads(r.text)\n",
        "\n",
        "      if r[\"status\"] == \"Success\":\n",
        "          return r[\"record_id\"]\n",
        "      elif \"err\" in r:        \n",
        "        print(r[\"err\"])\n",
        "        return None        \n",
        "      else:\n",
        "        print (\"Something is wrong, the notebook will not be submitted for grading\")\n",
        "        return None\n",
        "    \n",
        "    elif getAnswer() and getComplexity() and getAdditional() and getConcepts() and getComments() and getMentorSupport():\n",
        "      f = open(notebook + \".ipynb\", \"rb\")\n",
        "      file_hash = base64.b64encode(f.read())\n",
        "\n",
        "      data = {\"complexity\" : Complexity, \"additional\" :Additional, \n",
        "              \"concepts\" : Concepts, \"record_id\" : submission_id, \n",
        "              \"answer\" : Answer, \"id\" : Id, \"file_hash\" : file_hash,\n",
        "              \"notebook\" : notebook,\n",
        "              \"feedback_experiments_input\" : Comments,\n",
        "              \"feedback_mentor_support\": Mentor_support}\n",
        "      r = requests.post(url, data = data)\n",
        "      r = json.loads(r.text)\n",
        "      if \"err\" in r:        \n",
        "        print(r[\"err\"])\n",
        "        return None   \n",
        "      else:\n",
        "        print(\"Your submission is successful.\")\n",
        "        print(\"Ref Id:\", submission_id)\n",
        "        print(\"Date of submission: \", r[\"date\"])\n",
        "        print(\"Time of submission: \", r[\"time\"])\n",
        "        print(\"View your submissions: https://cds.iisc.talentsprint.com/notebook_submissions\")\n",
        "        #print(\"For any queries/discrepancies, please connect with mentors through the chat icon in LMS dashboard.\")\n",
        "        return submission_id\n",
        "    else: submission_id\n",
        "    \n",
        "\n",
        "def getAdditional():\n",
        "  try:\n",
        "    if not Additional: \n",
        "      raise NameError\n",
        "    else:\n",
        "      return Additional  \n",
        "  except NameError:\n",
        "    print (\"Please answer Additional Question\")\n",
        "    return None\n",
        "\n",
        "def getComplexity():\n",
        "  try:\n",
        "    if not Complexity:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Complexity\n",
        "  except NameError:\n",
        "    print (\"Please answer Complexity Question\")\n",
        "    return None\n",
        "  \n",
        "def getConcepts():\n",
        "  try:\n",
        "    if not Concepts:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Concepts\n",
        "  except NameError:\n",
        "    print (\"Please answer Concepts Question\")\n",
        "    return None\n",
        "  \n",
        "  \n",
        "# def getWalkthrough():\n",
        "#   try:\n",
        "#     if not Walkthrough:\n",
        "#       raise NameError\n",
        "#     else:\n",
        "#       return Walkthrough\n",
        "#   except NameError:\n",
        "#     print (\"Please answer Walkthrough Question\")\n",
        "#     return None\n",
        "  \n",
        "def getComments():\n",
        "  try:\n",
        "    if not Comments:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Comments\n",
        "  except NameError:\n",
        "    print (\"Please answer Comments Question\")\n",
        "    return None\n",
        "  \n",
        "\n",
        "def getMentorSupport():\n",
        "  try:\n",
        "    if not Mentor_support:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Mentor_support\n",
        "  except NameError:\n",
        "    print (\"Please answer Mentor support Question\")\n",
        "    return None\n",
        "\n",
        "def getAnswer():\n",
        "  try:\n",
        "    if not Answer:\n",
        "      raise NameError \n",
        "    else: \n",
        "      return Answer\n",
        "  except NameError:\n",
        "    print (\"Please answer Question\")\n",
        "    return None\n",
        "  \n",
        "\n",
        "def getId():\n",
        "  try: \n",
        "    return Id if Id else None\n",
        "  except NameError:\n",
        "    return None\n",
        "\n",
        "def getPassword():\n",
        "  try:\n",
        "    return password if password else None\n",
        "  except NameError:\n",
        "    return None\n",
        "\n",
        "submission_id = None\n",
        "### Setup \n",
        "if getPassword() and getId():\n",
        "  submission_id = submit_notebook()\n",
        "  if submission_id:\n",
        "    setup() \n",
        "else:\n",
        "  print (\"Please complete Id and Password cells before running setup\")\n",
        "\n"
      ],
      "id": "WBPPuGmBlDIN",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "foster-entity"
      },
      "source": [
        "#### Importing required packages"
      ],
      "id": "foster-entity"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tough-brooklyn"
      },
      "source": [
        "import statsmodels.api as sm\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import norm                             # A normal continuous random variable\n",
        "from numpy.random import seed                            # set the randomness\n",
        "from scipy import stats                                  # statistical operations\n",
        "import warnings\n",
        "warnings.simplefilter(\"ignore\")"
      ],
      "id": "tough-brooklyn",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "better-thesis"
      },
      "source": [
        "#### Load the data"
      ],
      "id": "better-thesis"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "voluntary-booth"
      },
      "source": [
        "# Read the dataset\n",
        "medical = pd.read_csv('insurance2.csv')\n",
        "medical.head()"
      ],
      "id": "voluntary-booth",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bibliographic-center"
      },
      "source": [
        "### Hypothesis Testing"
      ],
      "id": "bibliographic-center"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "corporate-anthony"
      },
      "source": [
        "Hypothesis testing or significance testing is a statistical method for testing a claim or hypothesis  about a parameter in a population, using data measured in a sample. It is basically an assumption that we make about the population parameter.\n",
        "There are basically two types, namely\n",
        "* null hypothesis\n",
        "* alternative hypothesis\n",
        "\n",
        "The purpose of a hypothesis test is to determine whether the null hypothesis is likely to be true given sample data. If there is little evidence against the null hypothesis given the data, you do not reject the null hypothesis. If the null hypothesis is unlikely given the data, you might reject the null in favor of the alternative hypothesis: that something interesting is going on. The exact form of the alternative hypothesis will depend on the specific test you are carrying out.\n",
        "\n",
        "Once you have the null and alternative hypothesis in hand, you choose a significance level (Î±). The significance level is a probability threshold that determines when you reject the null hypothesis. After carrying out a test, if the probability of getting a result as extreme as the one you observe due to chance is lower than the significance level, you reject the null hypothesis in favor of the alternative. This probability of seeing a result as extreme or more extreme than the one observed is known as the p-value.\n",
        "\n",
        "A z-test is a statistical test used to determine whether two population means are different when the variances are known and the sample size is large. A z-statistic, or z-score, is a number representing the result from the z-test. Z-tests assume the standard deviation is known, while t-tests assume it is unknown."
      ],
      "id": "corporate-anthony"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "worse-aircraft"
      },
      "source": [
        "**One-Sample Z-Test**\n",
        "\n",
        "We perform the One-Sample Z test when we want to compare a sample mean with the population mean. Let's create some dummy age data for the population of voters in the entire country and a sample of voters in North_Carolina and test the whether the average age of voters North_Carolina differs from the population"
      ],
      "id": "worse-aircraft"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "stone-world"
      },
      "source": [
        "np.random.seed(6)\n",
        "\n",
        "# Population ages\n",
        "population_ages1 = stats.poisson.rvs(loc=18, mu=35, size=150000)                  # .rvs provides random samples, To shift distribution use the loc parameter\n",
        "population_ages2 = stats.poisson.rvs(loc=18, mu=10, size=100000)\n",
        "population_ages = np.concatenate((population_ages1, population_ages2))\n",
        "\n",
        "# sample ages\n",
        "North_Carolina_ages1 = stats.poisson.rvs(loc=18, mu=30, size=30)\n",
        "North_Carolina_ages2 = stats.poisson.rvs(loc=18, mu=10, size=20)\n",
        "North_Carolina_ages = np.concatenate((North_Carolina_ages1, North_Carolina_ages2))\n",
        "\n",
        "print( population_ages.mean() )\n",
        "print( North_Carolina_ages.mean() )"
      ],
      "id": "stone-world",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "worth-spouse"
      },
      "source": [
        "To know more about `stats.poisson.rvs` click [here](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.poisson.html)"
      ],
      "id": "worth-spouse"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "complex-conditioning"
      },
      "source": [
        "Notice that we used a slightly different combination of distributions to generate the sample data for North_Carolina, so we know that the two means are different. Let's conduct a z-test at a 95% confidence level and see if it correctly rejects the null hypothesis that the sample comes from the same distribution as the population. To conduct a one sample z-test, we can use the `stats.ztest()` function by passing `alternative` argument as `smaller`."
      ],
      "id": "complex-conditioning"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hawaiian-canyon"
      },
      "source": [
        "sm.stats.ztest(x1= North_Carolina_ages, x2=None, value=43, alternative='smaller')     "
      ],
      "id": "hawaiian-canyon",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "southwest-division"
      },
      "source": [
        "The test result shows the test statistic \"z\" is equal to -2.574. The z score tells us how many standard deviations from the mean our score is. In this example, our score is -2.57 standard deviations below the mean. Also,  we can reject the null hypothesis that the mean of samples is equal the value or population mean (43)."
      ],
      "id": "southwest-division"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "electrical-tunnel"
      },
      "source": [
        "**Two-Sample Z-Test**\n",
        "\n",
        "The Two-Sample Z-test is used to compare the means of two samples to see if it is feasible that they come from the same population. The null hypothesis is: the population means are equal. The Z-test is preferred to the t-test for large samples (N > 30)  or when the variance is known, otherwise, the sample standard deviation is a more biased estimate of a population standard deviance than is allowable, and using a two-sample t-test should be considered."
      ],
      "id": "electrical-tunnel"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rotary-pixel"
      },
      "source": [
        "np.random.seed(12)\n",
        "South_Carolina_ages1 = stats.poisson.rvs(loc=18, mu=33, size=30)\n",
        "South_Carolina_ages2 = stats.poisson.rvs(loc=18, mu=13, size=20)\n",
        "South_Carolina_ages = np.concatenate((South_Carolina_ages1, South_Carolina_ages2))\n",
        "\n",
        "print( South_Carolina_ages.mean() )"
      ],
      "id": "rotary-pixel",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dying-credits"
      },
      "source": [
        "sm.stats.ztest(x1= North_Carolina_ages,\n",
        "                x2= South_Carolina_ages,\n",
        "                alternative='two-sided')    # Assume samples have equal variance"
      ],
      "id": "dying-credits",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "agricultural-protocol"
      },
      "source": [
        "The test yields a p-value of 0.0875, which means there is a 8.75% chance we'd see the difference in the means of the two sample data are not equal to value (here, it is 0 as here we calculate the difference of the two sample means), if these two groups tested are actually identical. If we were using a 95% confidence level we would fail to reject the null hypothesis, since the p-value is greater than the corresponding significance level of 5%."
      ],
      "id": "agricultural-protocol"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "chronic-father"
      },
      "source": [
        "**Paired Z-Test**\n",
        "\n",
        "The paired z-test may be used to test whether the mean difference of two populations is greater than, less than, or not equal to 0. Because the standard normal distribution is used to calculate critical values for the test, this test is often called the paired z-test. The paired z-test assumes that the population standard deviation of paired differences is known."
      ],
      "id": "chronic-father"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "arabic-bachelor"
      },
      "source": [
        "np.random.seed(11)\n",
        "\n",
        "before= stats.norm.rvs(scale=30, loc=250, size=100)\n",
        "after = before + stats.norm.rvs(scale=5, loc=-1.25, size=100)\n",
        "weight_df = pd.DataFrame({\"weight_before\":before,\n",
        "                          \"weight_after\":after,\n",
        "                          \"weight_change\":after-before})\n",
        "weight_df.describe()             # Check a summary of the data"
      ],
      "id": "arabic-bachelor",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "involved-elite"
      },
      "source": [
        "The summary shows that patients lost about 1.23 pounds on average after treatment. Let's conduct a paired z-test to see whether this difference is significant at a 95% confidence level"
      ],
      "id": "involved-elite"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "educational-silver"
      },
      "source": [
        "sm.stats.ztest(x1 = before,\n",
        "              x2 = after, alternative='two-sided')"
      ],
      "id": "educational-silver",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "second-headline"
      },
      "source": [
        "The p-value in the test output shows that the difference in means not equal to the value (0) is over 75%."
      ],
      "id": "second-headline"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QwUAqTCDdLuq"
      },
      "source": [
        "## Optional"
      ],
      "id": "QwUAqTCDdLuq"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fatal-explosion"
      },
      "source": [
        "### Linear Model\n",
        "\n",
        "Let's consider a simple equation y = 2 * x + 4 "
      ],
      "id": "fatal-explosion"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "endangered-limitation"
      },
      "source": [
        "# creating an array\n",
        "x_train = np.random.rand(100).astype(np.float32)\n",
        "\n",
        "# noise is added to randomize the data\n",
        "noise = np.random.normal(scale=0.1, size=len(x_train))\n",
        "# applying the equation to store the ground truth\n",
        "y_train = 2*x_train + 4 + noise\n",
        "\n",
        "# plot the data\n",
        "plt.plot(x_train, y_train, '.');"
      ],
      "id": "endangered-limitation",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dimensional-stations"
      },
      "source": [
        "#### Linear Regression model using sklearn\n",
        "\n",
        "Fit the model on the given data and get the predictions"
      ],
      "id": "dimensional-stations"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "viral-provision"
      },
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# reshape the data\n",
        "x_train = np.array(x_train).reshape(-1,1)\n",
        "y_train = np.array(y_train).reshape(-1,1)\n",
        "\n",
        "# Apply Linear regression from sklearn\n",
        "lm = LinearRegression()\n",
        "lm.fit(x_train, y_train)\n",
        "params = np.append(lm.intercept_,lm.coef_)\n",
        "predictions = lm.predict(x_train)"
      ],
      "id": "viral-provision",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dying-victory"
      },
      "source": [
        "#### Calculate the MSE, Standard Error,  and p-value\n",
        "\n",
        "Now that we have coefficients, to find if they are relevant to predict the target, p-value is used. The p-value for each term tests the null hypothesis that the coefficient is equal to zero (no effect). A low p-value (< 0.05) indicates that you can reject the null hypothesis.\n",
        "\n",
        "To know more about how to calculate p-value click [here](https://support.minitab.com/en-us/minitab/18/help-and-how-to/statistics/basic-statistics/supporting-topics/basics/manually-calculate-a-p-value)"
      ],
      "id": "dying-victory"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "grateful-ethernet"
      },
      "source": [
        "newX = np.append(np.ones((len(x_train),1)), x_train, axis=1)\n",
        "MSE = (sum((y_train-predictions)**2))/(len(newX)-len(newX[0]))\n",
        "\n",
        "# Calculating the standard error\n",
        "var_b = MSE*(np.linalg.inv(np.dot(newX.T,newX)).diagonal())\n",
        "sd_b = np.sqrt(var_b)\n",
        "ts_b = params/ sd_b\n",
        "\n",
        "# calculating p_values\n",
        "p_values =[2*(1-stats.t.cdf(np.abs(i),(len(newX)-len(newX[0])))) for i in ts_b]\n",
        "\n",
        "# rounding off the variablevalues\n",
        "sd_b = np.round(sd_b,3)\n",
        "ts_b = np.round(ts_b,3)\n",
        "p_values = np.round(p_values,3)\n",
        "params = np.round(params,4)"
      ],
      "id": "grateful-ethernet",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MTi7ixMrkz92"
      },
      "source": [
        "# Create a empty dataframe\n",
        "df1 = pd.DataFrame() \n",
        "# assign values to each column of a dataframe\n",
        "df1[\"Coefficients\"] = params\n",
        "df1[\"Standard Errors\"] = sd_b\n",
        "df1[\"t values\"] = ts_b\n",
        "df1[\"Probabilities\"] = p_values\n",
        "df1"
      ],
      "id": "MTi7ixMrkz92",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "employed-vacation"
      },
      "source": [
        "Now let's verify with OLS method using statsmodel"
      ],
      "id": "employed-vacation"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "impaired-overall"
      },
      "source": [
        "import statsmodels.api as sm\n",
        "x_train2 = sm.add_constant(x_train)\n",
        "# OLS method\n",
        "model = sm.OLS(y_train,x_train2).fit()\n",
        "model.summary()"
      ],
      "id": "impaired-overall",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "together-grace"
      },
      "source": [
        "To know more about `statsmodel.api.OLS` click [here](https://www.statsmodels.org/0.8.0/generated/statsmodels.regression.linear_model.OLS.html)"
      ],
      "id": "together-grace"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VHfHdGCP_n6Y"
      },
      "source": [
        "### Please answer the questions below to complete the experiment:\n",
        "\n",
        "\n"
      ],
      "id": "VHfHdGCP_n6Y"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VgSwVENIPcM6"
      },
      "source": [
        "# @title In a hypothesis test, what does the p value signify? { run: \"auto\", form-width: \"500px\", display-mode: \"form\" }\n",
        "Answer = \"\" #@param [\"\",\"smallest level of significance for rejection of Null Hypothesis\",\"largest level of significance for rejection of Null Hypothesis\",\"smallest level of significance for acceptance of Null Hypothesis\"]"
      ],
      "id": "VgSwVENIPcM6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NMzKSbLIgFzQ"
      },
      "source": [
        "#@title How was the experiment? { run: \"auto\", form-width: \"500px\", display-mode: \"form\" }\n",
        "Complexity = \"\" #@param [\"\",\"Too Simple, I am wasting time\", \"Good, But Not Challenging for me\", \"Good and Challenging for me\", \"Was Tough, but I did it\", \"Too Difficult for me\"]\n"
      ],
      "id": "NMzKSbLIgFzQ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DjcH1VWSFI2l"
      },
      "source": [
        "#@title If it was too easy, what more would you have liked to be added? If it was very difficult, what would you have liked to have been removed? { run: \"auto\", display-mode: \"form\" }\n",
        "Additional = \"\" #@param {type:\"string\"}\n"
      ],
      "id": "DjcH1VWSFI2l",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4VBk_4VTAxCM"
      },
      "source": [
        "#@title Can you identify the concepts from the lecture which this experiment covered? { run: \"auto\", vertical-output: true, display-mode: \"form\" }\n",
        "Concepts = \"\" #@param [\"\",\"Yes\", \"No\"]\n"
      ],
      "id": "4VBk_4VTAxCM",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XH91cL1JWH7m"
      },
      "source": [
        "#@title  Text and image description/explanation and code comments within the experiment: { run: \"auto\", vertical-output: true, display-mode: \"form\" }\n",
        "Comments = \"\" #@param [\"\",\"Very Useful\", \"Somewhat Useful\", \"Not Useful\", \"Didn't use\"]\n"
      ],
      "id": "XH91cL1JWH7m",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z8xLqj7VWIKW"
      },
      "source": [
        "#@title Mentor Support: { run: \"auto\", vertical-output: true, display-mode: \"form\" }\n",
        "Mentor_support = \"\" #@param [\"\",\"Very Useful\", \"Somewhat Useful\", \"Not Useful\", \"Didn't use\"]\n"
      ],
      "id": "z8xLqj7VWIKW",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FzAZHt1zw-Y-",
        "cellView": "form"
      },
      "source": [
        "#@title Run this cell to submit your notebook for grading { vertical-output: true }\n",
        "try:\n",
        "  if submission_id:\n",
        "      return_id = submit_notebook()\n",
        "      if return_id : submission_id = return_id\n",
        "  else:\n",
        "      print(\"Please complete the setup first.\")\n",
        "except NameError:\n",
        "  print (\"Please complete the setup first.\")"
      ],
      "id": "FzAZHt1zw-Y-",
      "execution_count": null,
      "outputs": []
    }
  ]
}